<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js navy">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Home Operations</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="././mdbook-admonish.css">

    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "navy";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('navy')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = null;
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><li class="part-title">Welcome</li><li class="spacer"></li><li class="chapter-item expanded "><a href="introduction.html">Introduction</a></li><li class="chapter-item expanded affix "><li class="part-title">Basement Notes</li><li class="spacer"></li><li class="chapter-item expanded "><a href="notes/nas.html">NAS</a></li><li class="chapter-item expanded "><a href="notes/opnsense.html">Opnsense</a></li><li class="chapter-item expanded "><a href="notes/pikvm.html">PiKVM</a></li><li class="chapter-item expanded "><a href="notes/proxmox-considerations.html">Proxmox Considerations</a></li><li class="chapter-item expanded "><a href="notes/s3-buckets.html">S3 buckets</a></li><li class="chapter-item expanded "><a href="notes/secret-variations-with-flux.html">Secret variations with Flux</a></li><li class="chapter-item expanded "><a href="notes/yaml-madness.html">YAML Madness</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Home Operations</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/onedr0p/home-ops" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<div id="admonition-warning" class="admonition warning">
<div class="admonition-title">
<p>Warning</p>
<p><a class="admonition-anchor-link" href="introduction.html#admonition-warning"></a></p>
</div>
<div>
<p>These docs contain information that relates to my setup. They may or may not work for you.</p>
</div>
</div>
<hr />
<br />
<div align="center">
<img src="https://camo.githubusercontent.com/5b298bf6b0596795602bd771c5bddbb963e83e0f/68747470733a2f2f692e696d6775722e636f6d2f7031527a586a512e706e67" align="center" width="144px" height="144px"/>
<h3 id="my-home-operations-repository-octocat"><a class="header" href="#my-home-operations-repository-octocat">My home operations repository :octocat:</a></h3>
<p><em>... managed with Flux, Renovate and GitHub Actions</em> ü§ñ</p>
</div>
<div align="center">
<p><a href="https://discord.gg/k8s-at-home"><img src="https://img.shields.io/discord/673534664354430999?style=for-the-badge&amp;label&amp;logo=discord&amp;logoColor=white&amp;color=blue" alt="Discord" /></a>¬†¬†¬†
<a href="https://k3s.io/"><img src="https://img.shields.io/badge/v1.26-blue?style=for-the-badge&amp;logo=kubernetes&amp;logoColor=white" alt="Kubernetes" /></a>¬†¬†¬†
<a href="https://github.com/onedr0p/home-ops/actions/workflows/renovate.yaml"><img src="https://img.shields.io/github/actions/workflow/status/onedr0p/home-ops/renovate.yaml?branch=main&amp;label=&amp;logo=renovatebot&amp;style=for-the-badge&amp;color=blue" alt="Renovate" /></a></p>
<p><a href="https://status.devbu.io"><img src="https://img.shields.io/uptimerobot/status/m793494864-dfc695db066960233ac70f45?color=brightgreeen&amp;label=Home%20Internet&amp;style=for-the-badge&amp;logo=v&amp;logoColor=white" alt="Home-Internet" /></a>¬†¬†¬†
<a href="https://status.devbu.io"><img src="https://img.shields.io/uptimerobot/status/m793599155-ba1b18e51c9f8653acd0f5c1?color=brightgreeen&amp;label=Status%20Page&amp;style=for-the-badge&amp;logo=statuspage&amp;logoColor=white" alt="Status-Page" /></a>¬†¬†¬†
<a href="https://status.devbu.io"><img src="https://img.shields.io/uptimerobot/status/m793494864-dfc695db066960233ac70f45?color=brightgreeen&amp;label=Alertmanager&amp;style=for-the-badge&amp;logo=prometheus&amp;logoColor=white" alt="Alertmanager" /></a></p>
</div>
<hr />
<h2 id="-overview"><a class="header" href="#-overview">üìñ Overview</a></h2>
<p>This is a mono repository for my home infrastructure and Kubernetes cluster. I try to adhere to Infrastructure as Code (IaC) and GitOps practices using the tools like <a href="https://www.ansible.com/">Ansible</a>, <a href="https://www.terraform.io/">Terraform</a>, <a href="https://kubernetes.io/">Kubernetes</a>, <a href="https://github.com/fluxcd/flux2">Flux</a>, <a href="https://github.com/renovatebot/renovate">Renovate</a> and <a href="https://github.com/features/actions">GitHub Actions</a>.</p>
<hr />
<h2 id="-kubernetes"><a class="header" href="#-kubernetes">‚õµ Kubernetes</a></h2>
<p>There is a template over at <a href="https://github.com/onedr0p/flux-cluster-template">onedr0p/flux-cluster-template</a> if you wanted to try and follow along with some of the practices I use here.</p>
<h3 id="installation"><a class="header" href="#installation">Installation</a></h3>
<p>My cluster is <a href="https://k3s.io/">k3s</a> provisioned overtop bare-metal Ubuntu Server using the <a href="https://www.ansible.com/">Ansible</a> galaxy role <a href="https://github.com/PyratLabs/ansible-role-k3s">ansible-role-k3s</a>. This is a semi hyper-converged cluster, workloads and block storage are sharing the same available resources on my nodes while I have a separate server for (NFS) file storage.</p>
<p>üî∏ <em><a href="./infrastructure/kubernetes/servers/">Click here</a> to see my Ansible playbooks and roles.</em></p>
<h3 id="core-components"><a class="header" href="#core-components">Core Components</a></h3>
<ul>
<li><a href="https://github.com/actions/actions-runner-controller">actions-runner-controller</a>: Self-hosted Github runners.</li>
<li><a href="https://github.com/projectcalico/calico">calico</a>: Internal Kubernetes networking plugin.</li>
<li><a href="https://cert-manager.io/docs/">cert-manager</a>: Creates SSL certificates for services in my Kubernetes cluster.</li>
<li><a href="https://github.com/kubernetes-sigs/external-dns">external-dns</a>: Automatically manages DNS records from my cluster in a cloud DNS provider.</li>
<li><a href="https://github.com/external-secrets/external-secrets/">external-secrets</a>: Managed Kubernetes secrets using <a href="https://github.com/1Password/connect">1Password Connect</a>.</li>
<li><a href="https://github.com/kubernetes/ingress-nginx/">ingress-nginx</a>: Ingress controller to expose HTTP traffic to pods over DNS.</li>
<li><a href="https://github.com/rook/rook">rook</a>: Distributed block storage for peristent storage.</li>
<li><a href="https://toolkit.fluxcd.io/guides/mozilla-sops/">sops</a>: Managed secrets for Kubernetes, Ansible and Terraform which are commited to Git.</li>
<li><a href="https://github.com/weaveworks/tf-controller">tf-controller</a>: Additional Flux component used to run Terraform from within a Kubernetes cluster.</li>
<li><a href="https://github.com/backube/volsync">volsync</a> and <a href="https://github.com/backube/snapscheduler">snapscheduler</a>: Backup and recovery of persistent volume claims.</li>
</ul>
<h3 id="gitops"><a class="header" href="#gitops">GitOps</a></h3>
<p><a href="https://github.com/fluxcd/flux2">Flux</a> watches my <a href="./kubernetes/">kubernetes</a> folder (see Directories below) and makes the changes to my cluster based on the YAML manifests.</p>
<p>The way Flux works for me here is it will recursively search the <a href="./kubernetes/apps">kubernetes/apps</a> folder until it finds the most top level <code>kustomization.yaml</code> per directory and then apply all the resources listed in it. That aforementioned <code>kustomization.yaml</code> will generally only have a namespace resource and one or many Flux kustomizations. Those Flux kustomizations will generally have a <code>HelmRelease</code> or other resources related to the application underneath it which will be applied.</p>
<p><a href="https://github.com/renovatebot/renovate">Renovate</a> watches my <strong>entire</strong> repository looking for dependency updates, when they are found a PR is automatically created. When some PRs are merged <a href="https://github.com/fluxcd/flux2">Flux</a> applies the changes to my cluster.</p>
<h3 id="directories"><a class="header" href="#directories">Directories</a></h3>
<p>This Git repository contains the following directories under <a href="./kubernetes/">kubernetes</a>.</p>
<pre><code class="language-sh">üìÅ kubernetes      # Kubernetes cluster defined as code
‚îú‚îÄüìÅ bootstrap     # Flux installation
‚îú‚îÄüìÅ flux          # Main Flux configuration of repository
‚îî‚îÄüìÅ apps          # Apps deployed into my cluster grouped by namespace (see below)
</code></pre>
<h3 id="cluster-layout"><a class="header" href="#cluster-layout">Cluster layout</a></h3>
<p>Below is a a high level look at the layout of how my directory structure with Flux works. In this brief example you are able to see that <code>authelia</code> will not be able to run until <code>lldap</code> and  <code>cloudnative-pg</code> are running. It also shows that the <code>Cluster</code> custom resource depends on the <code>cloudnative-pg</code> Helm chart. This is needed because <code>cloudnative-pg</code> installs the <code>Cluster</code> custom resource definition in the Helm chart.</p>
<pre><code class="language-python"># Key: &lt;kind&gt; :: &lt;metadata.name&gt;
GitRepository :: home-ops-kubernetes
    Kustomization :: cluster
        Kustomization :: cluster-apps
            Kustomization :: cluster-apps-cloudnative-pg
                HelmRelease :: cloudnative-pg
            Kustomization :: cluster-apps-cloudnative-pg-cluster
                DependsOn:
                    Kustomization :: cluster-apps-cloudnative-pg
                Cluster :: postgres
            Kustomization :: cluster-apps-lldap
                HelmRelease :: lldap
                DependsOn:
                    Kustomization :: cluster-apps-cloudnative-pg-cluster
            Kustomization :: cluster-apps-authelia
                DependsOn:
                    Kustomization :: cluster-apps-lldap
                    Kustomization :: cluster-apps-cloudnative-pg-cluster
                HelmRelease :: authelia
</code></pre>
<h3 id="networking"><a class="header" href="#networking">Networking</a></h3>
<details>
  <summary>Click to see a high level network diagram</summary>
<img src="https://raw.githubusercontent.com/onedr0p/home-ops/main/docs/src/assets/networks.png" align="center" width="600px" alt="dns"/>
</details>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>CIDR</th></tr></thead><tbody>
<tr><td>Management VLAN</td><td><code>192.168.1.0/24</code></td></tr>
<tr><td>Kubernetes Nodes VLAN</td><td><code>192.168.42.0/24</code></td></tr>
<tr><td>Kubernetes external services (Calico w/ BGP)</td><td><code>192.168.69.0/24</code></td></tr>
<tr><td>Kubernetes pods (Calico w/ BGP)</td><td><code>10.42.0.0/16</code></td></tr>
<tr><td>Kubernetes services (Calico w/ BGP)</td><td><code>10.43.0.0/16</code></td></tr>
</tbody></table>
</div>
<ul>
<li>HAProxy is configured on my <code>VyOS</code> router for the Kubernetes Control Plane Load Balancer.</li>
<li>Calico is configured with <code>externalIPs</code> to expose Kubernetes services with their own IP over BGP which is configured on my router.</li>
</ul>
<hr />
<h2 id="-cloud-dependencies"><a class="header" href="#-cloud-dependencies">‚òÅÔ∏è Cloud Dependencies</a></h2>
<p>While most of my infrastructure and workloads are selfhosted I do rely upon the cloud for certain key parts of my setup. This saves me from having to worry about two things. (1) Dealing with chicken/egg scenarios and (2) services I critically need whether my cluster is online or not.</p>
<p>The alternative solution to these two problems would be to host a Kubernetes cluster in the cloud and deploy applications like <a href="https://www.vaultproject.io/">HCVault</a>, <a href="https://github.com/dani-garcia/vaultwarden">Vaultwarden</a>, <a href="https://ntfy.sh/">ntfy</a>, and <a href="https://gatus.io/">Gatus</a>. However, maintaining another cluster and monitoring another group of workloads is a lot more time and effort than I am willing to put in.</p>
<div class="table-wrapper"><table><thead><tr><th>Service</th><th>Use</th><th>Cost</th></tr></thead><tbody>
<tr><td><a href="https://1password.com/">1Password</a></td><td>Secrets with <a href="https://external-secrets.io/">External Secrets</a></td><td>~$65/yr</td></tr>
<tr><td><a href="https://www.cloudflare.com/">Cloudflare</a></td><td>Domain and R2</td><td>~$30/yr</td></tr>
<tr><td><a href="https://migadu.com/">Migadu</a></td><td>Email hosting</td><td>~$20/yr</td></tr>
<tr><td><a href="https://cloud.google.com/">GCP</a></td><td>Voice interactions with Home Assistant over Google Assistant</td><td>Free</td></tr>
<tr><td><a href="https://github.com/">GitHub</a></td><td>Hosting this repository and continuous integration/deployments</td><td>Free</td></tr>
<tr><td><a href="https://www.newsgroup.ninja/">Newsgroup Ninja</a></td><td>Usenet access</td><td>~$70/yr</td></tr>
<tr><td><a href="https://nextdns.io/">NextDNS</a></td><td>My routers DNS server which includes AdBlocking</td><td>~$20/yr</td></tr>
<tr><td><a href="https://pushover.net/">Pushover</a></td><td>Kubernetes Alerts and application notifications</td><td>Free</td></tr>
<tr><td><a href="https://www.terraform.io/">Terraform Cloud</a></td><td>Storing Terraform state</td><td>Free</td></tr>
<tr><td><a href="https://uptimerobot.com/">UptimeRobot</a></td><td>Monitoring internet connectivity and external facing applications</td><td>~$60/yr</td></tr>
<tr><td></td><td></td><td>Total: ~$27/mo</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="-dns"><a class="header" href="#-dns">üåê DNS</a></h2>
<h3 id="internal-dns"><a class="header" href="#internal-dns">Internal DNS</a></h3>
<p><a href="https://github.com/isc-projects/bind9">Bind9</a> and <a href="https://dnsdist.org/">dnsdist</a> are deployed on Vyos as containers. In my cluster <a href="https://github.com/kubernetes-sigs/external-dns">external-dns</a> is deployed with the RFC2136 provider that populates Bind9 with all my ingresses DNS records.</p>
<p>dnsdist has some downstream DNS servers configured such as Bind9 (above) and <a href="https://nextdns.io/">NextDNS</a> profiles. All my clients use dnsdist as the upstream DNS server, this allows for more granularity with configuring DNS across my networks. These could be things like giving each of my VLANs a specific NextDNS profile, or having all requests for my domain forward to Bind9 on certain networks, or only using 1.1.1.1 instead of NextDNS on certain networks where adblocking isn't needed.</p>
<h3 id="external-dns"><a class="header" href="#external-dns">External DNS</a></h3>
<p>Another <code>external-dns</code> instance is deployed in my cluster and configure to sync DNS records to <a href="https://www.cloudflare.com/">Cloudflare</a>. The only ingresses this <code>external-dns</code> instance looks at to gather DNS records to put in <code>Cloudflare</code> are ones that have an annotation of <code>external-dns.alpha.kubernetes.io/target</code>.</p>
<hr />
<h2 id="-hardware"><a class="header" href="#-hardware">üîß Hardware</a></h2>
<details>
  <summary>Click to see da rack!</summary>
<img src="https://user-images.githubusercontent.com/213795/172947261-65a82dcd-3274-45bd-aabf-140d60a04aa9.png" align="center" width="200px" alt="rack"/>
</details>
<div class="table-wrapper"><table><thead><tr><th>Device</th><th>Count</th><th>OS Disk Size</th><th>Data Disk Size</th><th>Ram</th><th>Operating System</th><th>Purpose</th></tr></thead><tbody>
<tr><td>Intel NUC8i5BEH</td><td>3</td><td>1TB SSD</td><td>1TB NVMe (rook-ceph)</td><td>64GB</td><td>Debian</td><td>Kubernetes Masters</td></tr>
<tr><td>Intel NUC8i7BEH</td><td>3</td><td>1TB SSD</td><td>1TB NVMe (rook-ceph)</td><td>64GB</td><td>Debian</td><td>Kubernetes Workers</td></tr>
<tr><td>PowerEdge T340</td><td>1</td><td>2TB SSD</td><td>8x12TB ZFS (mirrored vdevs)</td><td>64GB</td><td>Ubuntu</td><td>NFS + Backup Server</td></tr>
<tr><td>Lenovo SA120</td><td>1</td><td>-</td><td>6x12TB (+2 hot spares)</td><td>-</td><td>-</td><td>DAS</td></tr>
<tr><td>Raspberry Pi 4</td><td>1</td><td>32GB (SD)</td><td>-</td><td>4GB</td><td>PiKVM (Arch)</td><td>Network KVM</td></tr>
<tr><td>TESmart 8 Port KVM Switch</td><td>1</td><td>-</td><td>-</td><td>-</td><td>-</td><td>Network KVM (PiKVM)</td></tr>
<tr><td>HP EliteDesk 800 G3 SFF</td><td>1</td><td>256GB NVMe</td><td>-</td><td>8GB</td><td>Vyos (Debian)</td><td>Router</td></tr>
<tr><td>Unifi US-16-XG</td><td>1</td><td>-</td><td>-</td><td>-</td><td>-</td><td>10Gb Core Switch</td></tr>
<tr><td>Unifi USW-Enterprise-24-PoE</td><td>1</td><td>-</td><td>-</td><td>-</td><td>-</td><td>2.5Gb PoE Switch</td></tr>
<tr><td>APC SMT1500RM2U w/ NIC</td><td>1</td><td>-</td><td>-</td><td>-</td><td>-</td><td>UPS</td></tr>
<tr><td>Unifi USP PDU Pro</td><td>1</td><td>-</td><td>-</td><td>-</td><td>-</td><td>PDU</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="-stargazers"><a class="header" href="#-stargazers">‚≠ê Stargazers</a></h2>
<div align="center">
<p><a href="https://star-history.com/#onedr0p/home-ops&amp;Date"><img src="https://api.star-history.com/svg?repos=onedr0p/home-ops&amp;type=Date" alt="Star History Chart" /></a></p>
</div>
<hr />
<h2 id="-gratitude-and-thanks"><a class="header" href="#-gratitude-and-thanks">ü§ù Gratitude and Thanks</a></h2>
<p>Thanks to all the people who donate their time to the <a href="https://discord.gg/k8s-at-home">Kubernetes @Home</a> Discord community. A lot of inspiration for my cluster comes from the people that have shared their clusters using the <a href="https://github.com/topics/k8s-at-home">k8s-at-home</a> GitHub topic. Be sure to check out the <a href="https://nanne.dev/k8s-at-home-search/">Kubernetes @Home search</a> for ideas on how to deploy applications or get ideas on what you can deploy.</p>
<hr />
<h2 id="-changelog"><a class="header" href="#-changelog">üìú Changelog</a></h2>
<p>See my <em>awful</em> <a href="https://github.com/onedr0p/home-ops/commits/main">commit history</a></p>
<hr />
<h2 id="-license"><a class="header" href="#-license">üîè License</a></h2>
<p>See <a href="./LICENSE">LICENSE</a></p>
<footer id="open-on-gh"><a href="https://github.com/onedr0p/home-ops/edit/main/docs/src/introduction.md">Edit this page on GitHub</a></footer><div style="break-before: page; page-break-before: always;"></div><h1 id="nas"><a class="header" href="#nas">NAS</a></h1>
<p>Outside of using <a href="https://github.com/ansible/ansible">Ansible</a> for configuring the OS, there are some manual steps I did to set up ZFS on Ubuntu.</p>
<h2 id="zfs"><a class="header" href="#zfs">ZFS</a></h2>
<h3 id="mirrored-zpool"><a class="header" href="#mirrored-zpool">Mirrored Zpool</a></h3>
<ol>
<li>
<p>Create initial pool and set configuration</p>
<pre><code class="language-sh">sudo zpool create -o ashift=12 -f eros mirror \
    /dev/disk/by-id/scsi-SATA_WDC_WD120EDGZ-11_9LHWA5KG \
    /dev/disk/by-id/scsi-SATA_WDC_WD120EMFZ-11_9MG0AHZA
sudo zfs set atime=off eros
sudo zfs set compression=lz4 eros
</code></pre>
</li>
<li>
<p>Attach more mirrors</p>
<pre><code class="language-sh">sudo zpool add eros mirror \
    /dev/disk/by-id/scsi-SATA_ST12000VN0007-2G_ZCH0B3D2 \
    /dev/disk/by-id/scsi-SATA_WDC_WD120EMFZ-11_X1G3B01L
</code></pre>
</li>
<li>
<p>Add spares</p>
<pre><code class="language-sh">sudo zpool add -f eros spare \
    /dev/disk/by-id/scsi-SATA_WDC_WD120EMFZ-11_QGGETR5T
</code></pre>
</li>
</ol>
<h3 id="datasets"><a class="header" href="#datasets">Datasets</a></h3>
<ol>
<li>
<p>Create datasets</p>
<pre><code class="language-sh">sudo zfs create eros/Apps
sudo zfs create eros/Apps/MinIO
sudo zfs create eros/Media
</code></pre>
</li>
<li>
<p>Share dataset over NFS</p>
<pre><code class="language-sh">sudo zfs set \
    sharenfs=&quot;no_subtree_check,all_squash,anonuid=568,anongid=100,rw=@192.168.42.0/24,rw=@192.168.1.0/24,ro=192.168.150.21,ro=192.168.150.28&quot; \
    eros/Media
sudo zfs set \
    sharenfs=&quot;no_subtree_check,all_squash,anonuid=568,anongid=100,rw=@192.168.42.0/24,rw=@192.168.1.0/24&quot; \
    eros/Apps/MinIO
</code></pre>
</li>
<li>
<p>Dataset Permissions</p>
<pre><code class="language-sh">sudo chmod 770 /eros/Media
sudo chown -R devin:users /eros/Media
</code></pre>
</li>
</ol>
<h3 id="snapshots"><a class="header" href="#snapshots">Snapshots</a></h3>
<p>Install zrepl by following <a href="https://zrepl.github.io/installation/apt-repos.html">these</a> instructions.</p>
<ol>
<li>
<p>Add or replace the file <code>/etc/zrepl/zrepl.yml</code></p>
<pre><code class="language-yaml">global:
  logging:
    - type: syslog
      format: human
      level: warn
  monitoring:
    - type: prometheus
      listen: :9811
      listen_freebind: true

jobs:
  - name: daily
    type: snap
    filesystems:
      &quot;eros&lt;&quot;: true
    snapshotting:
      type: cron
      cron: &quot;0 3 * * *&quot;
      prefix: zrepl_daily_
      timestamp_format: dense
    pruning:
      keep:
        - type: last_n
          count: 7
          regex: &quot;^zrepl_daily_.*$&quot;
</code></pre>
</li>
<li>
<p>Start and enable zrepl</p>
<pre><code class="language-sh">sudo systemctl enable --now zrepl.service
</code></pre>
</li>
<li>
<p>Give a local user access to a specific datasets snapshots</p>
<pre><code class="language-sh">sudo zfs allow -u jeff send,snapshot,hold eros/Media
</code></pre>
</li>
</ol>
<h2 id="nfs"><a class="header" href="#nfs">NFS</a></h2>
<h3 id="non-zfs-nfs-shares"><a class="header" href="#non-zfs-nfs-shares">Non ZFS NFS Shares</a></h3>
<ol>
<li>
<p>Add or replace file <code>/etc/exports.d/local.exports</code></p>
<pre><code class="language-text">/share/PVCs 192.168.1.0/24(sec=sys,rw,no_subtree_check,all_squash,anonuid=568,anongid=100)
/share/PVCs 192.168.42.0/24(sec=sys,rw,no_subtree_check,all_squash,anonuid=568,anongid=100)
</code></pre>
</li>
<li>
<p>Dataset Permissions</p>
<pre><code class="language-sh">sudo chmod 770 /share/PVCs
sudo chown -R devin:users /share/PVCs
</code></pre>
</li>
<li>
<p>Reload exports</p>
<pre><code class="language-sh">sudo exportfs -arv
</code></pre>
</li>
</ol>
<h2 id="misc"><a class="header" href="#misc">Misc</a></h2>
<h3 id="badblocks"><a class="header" href="#badblocks">Badblocks</a></h3>
<div id="admonition-warning" class="admonition warning">
<div class="admonition-title">
<p>Warning</p>
<p><a class="admonition-anchor-link" href="notes/nas.html#admonition-warning"></a></p>
</div>
<div>
<p>This command is <strong>very destructive</strong> and should only be used to check for bad sectors</p>
</div>
</div>
<pre><code class="language-sh">sudo badblocks -b 4096 -wsv /dev/disk/by-id/scsi-SATA_ST12000VN0007-2G_ZJV01MC5
</code></pre>
<h3 id="lenovo-sa120"><a class="header" href="#lenovo-sa120">Lenovo SA120</a></h3>
<p>Due to the loudness of the fans, they can be adjusted by using <a href="https://github.com/AndrewX192/lenovo-sa120-fanspeed-utility.git">AndrewX192/lenovo-sa120-fanspeed-utility</a>.</p>
<footer id="open-on-gh"><a href="https://github.com/onedr0p/home-ops/edit/main/docs/src/notes/nas.md">Edit this page on GitHub</a></footer><div style="break-before: page; page-break-before: always;"></div><h1 id="opnsense"><a class="header" href="#opnsense">Opnsense</a></h1>
<div id="admonition-warning" class="admonition warning">
<div class="admonition-title">
<p>Warning</p>
<p><a class="admonition-anchor-link" href="notes/opnsense.html#admonition-warning"></a></p>
</div>
<div>
<p>I am no longer use Opnsense therefor this document will likely not be updated anymore.</p>
</div>
</div>
<h2 id="bgp"><a class="header" href="#bgp">BGP</a></h2>
<p>Instead of using Metallb for L2/L3 load balancer IPs I am using the Kubernetes Calico CNI with BGP which allows me to advertise load balancer IPs directly over BGP. This has some benefits like having equal cost multipath (ECMP) for scaled workloads in my cluster.</p>
<ol>
<li>Routing &gt; BPG | General
<ol>
<li><code>enable</code> = <code>true</code></li>
<li><code>BGP AS Number</code> = <code>64512</code></li>
<li><code>Network</code> = <code>192.168.42.0/24</code> (Subnet your Kubernetes nodes are on)</li>
<li>Save</li>
</ol>
</li>
<li>Routing &gt; BGP | Neighbors
<ul>
<li>Add a neighbor for each Kubernetes node
<ol>
<li><code>Enabled</code> = <code>true</code></li>
<li><code>Peer-IP</code> = <code>192.168.42.x</code> (Kubernetes Node IP)</li>
<li><code>Remote AS</code> = <code>64512</code></li>
<li><code>Update-Source Interface</code> = <code>HOME_SERVER</code> (VLAN of Kubernetes nodes)</li>
<li>Save</li>
<li>Continue adding neighbors until all your nodes are present</li>
</ol>
</li>
</ul>
</li>
<li>Routing &gt; General
<ol>
<li><code>Enable</code> = <code>true</code></li>
<li>Save</li>
</ol>
</li>
<li>System &gt; Settings &gt; Tunables
<ol>
<li>Add <code>net.route.multipath</code> and set the value to <code>1</code></li>
<li>Save</li>
</ol>
</li>
<li>Reboot</li>
<li>Verify
<ol>
<li>Routing &gt; Diagnostics | Summary</li>
</ol>
</li>
</ol>
<div id="admonition-warning-1" class="admonition warning">
<div class="admonition-title">
<p>Warning</p>
<p><a class="admonition-anchor-link" href="notes/opnsense.html#admonition-warning-1"></a></p>
</div>
<div>
<p>Without updating the configuration described in <strong>step 4</strong> the routes from a client will only take a <strong>single path to your Kubernetes workloads</strong> even if they are scaled to more than one.</p>
</div>
</div>
<h2 id="haproxy"><a class="header" href="#haproxy">HAProxy</a></h2>
<p>While kube-vip is very nice for having a API server ready to go and running in your cluster I had issues with mixing layer 2 and layer 3 between Calico in BGP and kube-vip using L2 ARP. You also cannot run Calico in BGP with kube-vip in BGP, they will fight and you will lose. Instead I choose to use Haproxy which you can install from the Opnsense Plugins.</p>
<ol>
<li>Services &gt; HAProxy | Real Servers
<ul>
<li>Add a server for each <strong>master node</strong> in your Kubernetes cluster
<ol>
<li><code>Enabled</code> = <code>true</code></li>
<li><code>Name or Prefix</code> = <code>k8s-apiserver-x</code></li>
<li><code>FQDN or IP</code> = <code>192.168.42.x</code></li>
<li><code>Port</code> = <code>6443</code></li>
<li><code>Verify SSL Certificate</code> = <code>false</code></li>
<li>Apply/Save</li>
<li>Continue adding servers until all your <strong>master nodes</strong> are present</li>
</ol>
</li>
</ul>
</li>
<li>Services &gt; HAProxy | Rules &amp; Checks &gt; Health Monitors
<ol>
<li><code>Name</code> = <code>k8s-apiserver-health</code></li>
<li><code>SSL preferences</code> = <code>Force SSL for health checks</code></li>
<li><code>Port to check</code> = <code>6443</code></li>
<li><code>HTTP method</code> = <code>GET</code></li>
<li><code>Request URI</code> = <code>/healthz</code></li>
<li><code>HTTP version</code> = <code>HTTP/1.1</code></li>
<li>Apply/Save</li>
</ol>
</li>
<li>Services &gt; HAProxy | Virtual Services &gt; Backend Pools
<ol>
<li><code>Enabled</code> = <code>true</code></li>
<li><code>Name</code> = <code>k8s-apiserver-be</code></li>
<li><code>Mode</code> = <code>TCP (Layer 4)</code></li>
<li><code>Servers</code> = <code>k8s-apiserver-x</code> ... (Add one for each server you created. Use TAB key to complete typing each server)</li>
<li><code>Source address</code> = <code>192.168.1.1</code> (Your Opnsense IP address)</li>
<li><code>Enable Health Checking</code> = <code>true</code></li>
<li><code>Health Monitor</code> = <code>k8s-apiserver-health</code></li>
<li>Apply/Save</li>
</ol>
</li>
<li>Services &gt; HAProxy | Virtual Services &gt; Public Services
<ol>
<li><code>Enabled</code> = <code>true</code></li>
<li><code>Name</code> = <code>k8s-apiserver-fe</code></li>
<li><code>Listen Addresses</code> = <code>192.168.1.1:6443</code> (Your Opnsense IP address. Use TAB key to complete typing a listen address)</li>
<li><code>Type</code> = <code>TCP</code></li>
<li><code>Default Backend Pool</code> = <code>k8s-apiserver-be</code></li>
<li>Apply/Save</li>
</ol>
</li>
<li>Services &gt; HAProxy | Settings &gt; Service
<ol>
<li><code>Enable HAProxy</code> = <code>true</code></li>
<li>Apply/Save</li>
</ol>
</li>
<li>Services &gt; HAProxy | Settings &gt; Global Parameters
<ol>
<li><code>Verify SSL Server Certificates</code> = <code>disable-verify</code></li>
<li>Apply/Save</li>
</ol>
</li>
<li>Services &gt; HAProxy | Settings &gt; Default Parameters
<ol>
<li><code>Client Timeout</code> = <code>4h</code></li>
<li><code>Connection Timeout</code> = <code>10s</code></li>
<li><code>Server Timeout</code> = <code>4h</code></li>
<li>Apply/Save</li>
</ol>
</li>
</ol>
<h2 id="receive-side-scaling-rss"><a class="header" href="#receive-side-scaling-rss">Receive Side Scaling (RSS)</a></h2>
<p>RSS is used to distribute packets over CPU cores using a hashing function ‚Äì either with support in the hardware which offloads the hashing for you, or in software. Click <a href="https://forum.opnsense.org/index.php?topic=24409.0">here</a> to learn more about it.</p>
<ol>
<li>System &gt; Settings &gt; Tunables
<ol>
<li>Add <code>net.inet.rss.enabled</code> and set the value to <code>1</code></li>
<li>Add <code>net.inet.rss.bits</code> and set to <code>2</code></li>
<li>Add <code>net.isr.dispatch</code> and set to <code>hybrid</code></li>
<li>Add <code>net.isr.bindthreads</code> and set to <code>1</code></li>
<li>Add <code>net.isr.maxthreads</code> and set to <code>-1</code></li>
<li>Save</li>
</ol>
</li>
<li>Reboot</li>
<li>Verify with <code>sudo netstat -Q</code>
<pre><code class="language-text">Configuration:
Setting                        Current        Limit
Thread count                         8            8
Default queue limit                256        10240
Dispatch policy                 hybrid          n/a
Threads bound to CPUs          enabled          n/a
</code></pre>
</li>
</ol>
<h2 id="syslog"><a class="header" href="#syslog">Syslog</a></h2>
<p>Firewall logs are being sent to <a href="https://github.com/vectordotdev/vector">Vector</a> which is running in my Kubernetes cluster. Vector is then shipping the logs to <a href="https://github.com/grafana/loki">Loki</a> which is also running in my cluster.</p>
<ol>
<li>System &gt; Settings &gt; Logging / targets
<ul>
<li>Add new logging target
<ol>
<li><code>Enabled</code> = <code>true</code></li>
<li><code>Transport</code> = <code>UDP(4)</code></li>
<li><code>Applications</code> = <code>filter (filterlog)</code></li>
<li><code>Hostname</code> = <code>192.168.69.111</code> (Loki's Load Balancer IP)</li>
<li><code>Port</code> = <code>5140</code></li>
<li><code>rfc5424</code> = <code>true</code></li>
<li>Save</li>
</ol>
</li>
</ul>
</li>
</ol>
<h2 id="smtp-relay"><a class="header" href="#smtp-relay">SMTP Relay</a></h2>
<p>To ease the use of application configuration I have a SMTP Relay running on Opnsense using the Postfix plugin. From applications deployed in my Kubernetes cluster, to my nas, to my printer, all use the same configuration for SMTP without authentication.</p>
<ol>
<li>System &gt; Services &gt; Postfix &gt; General
<ol>
<li><code>SMTP Client Security</code> = <code>encrypt</code></li>
<li><code>Smart Host</code> = <code>[smtp.fastmail.com]:465</code></li>
<li><code>Enable SMTP Authentication</code> = <code>true</code></li>
<li><code>Authentication Username</code> = <code>devin@&lt;email-domain&gt;</code></li>
<li><code>Authentication Password</code> = <code>&lt;app-password&gt;</code></li>
<li><code>Permit SASL Authenticated</code> = <code>false</code></li>
<li>Save</li>
</ol>
</li>
<li>System &gt; Services &gt; Postfix &gt; Domains
<ul>
<li>Add new domain
<ol>
<li><code>Domainname</code> = <code>&lt;email-domain&gt;</code></li>
<li><code>Destination</code> = <code>[smtp.fastmail.com]:465</code></li>
<li>Save</li>
</ol>
</li>
<li>Apply</li>
</ul>
</li>
<li>System &gt; Services &gt; Postfix &gt; Senders
<ul>
<li>Add new sender
<ol>
<li><code>Enabled</code> = <code>true</code></li>
<li><code>Sender Address</code> = <code>admin@&lt;email-domain&gt;</code></li>
<li>Save</li>
</ol>
</li>
<li>Apply</li>
</ul>
</li>
<li>Verify
<pre><code class="language-sh">swaks --server opnsense.turbo.ac --port 25 --to &lt;email-address&gt; --from &lt;email-address&gt;
</code></pre>
</li>
</ol>
<footer id="open-on-gh"><a href="https://github.com/onedr0p/home-ops/edit/main/docs/src/notes/opnsense.md">Edit this page on GitHub</a></footer><div style="break-before: page; page-break-before: always;"></div><h1 id="pikvm"><a class="header" href="#pikvm">PiKVM</a></h1>
<h2 id="update-pikvm"><a class="header" href="#update-pikvm">Update PiKVM</a></h2>
<pre><code class="language-sh">rw; pacman -Syyu
reboot
</code></pre>
<h2 id="load-tesmart-kvm"><a class="header" href="#load-tesmart-kvm">Load TESmart KVM</a></h2>
<ol>
<li>
<p>Add or replace the file <code>/etc/kvmd/override.yaml</code></p>
<pre><code class="language-yaml">kvmd:
    gpio:
        drivers:
            tes:
                type: tesmart
                host: 192.168.1.10
                port: 5000
        scheme:
            server0_led:
                driver: tes
                pin: 0
                mode: input
            server0_switch:
                driver: tes
                pin: 0
                mode: output
                switch: false
            server1_led:
                driver: tes
                pin: 1
                mode: input
            server1_switch:
                driver: tes
                pin: 1
                mode: output
                switch: false
            server2_led:
                driver: tes
                pin: 2
                mode: input
            server2_switch:
                driver: tes
                pin: 2
                mode: output
                switch: false
            server3_led:
                driver: tes
                pin: 3
                mode: input
            server3_switch:
                driver: tes
                pin: 3
                mode: output
                switch: false
            server4_led:
                driver: tes
                pin: 4
                mode: input
            server4_switch:
                driver: tes
                pin: 4
                mode: output
                switch: false
            server5_led:
                driver: tes
                pin: 5
                mode: input
            server5_switch:
                driver: tes
                pin: 5
                mode: output
                switch: false
            server6_led:
                driver: tes
                pin: 6
                mode: input
            server6_switch:
                driver: tes
                pin: 6
                mode: output
                switch: false
            server7_led:
                driver: tes
                pin: 7
                mode: input
            server7_switch:
                driver: tes
                pin: 7
                mode: output
                switch: false
        view:
            table:
                - [&quot;TESMART Switch&quot;]
                - []
                - [&quot;#device-0&quot;, server0_led, server0_switch|Switch]
                - [&quot;#device-1&quot;, server1_led, server1_switch|Switch]
                - [&quot;#device-2&quot;, server2_led, server2_switch|Switch]
                - [&quot;#device-3&quot;, server3_led, server3_switch|Switch]
                - [&quot;#device-4&quot;, server4_led, server4_switch|Switch]
                - [&quot;#device-5&quot;, server5_led, server5_switch|Switch]
                - [&quot;#device-6&quot;, server6_led, server6_switch|Switch]
                - [&quot;#device-7&quot;, server7_led, server7_switch|Switch]
</code></pre>
</li>
<li>
<p>Restart kvmd</p>
<pre><code class="language-sh">systemctl restart kvmd.service
</code></pre>
</li>
</ol>
<h2 id="load-custom-edid"><a class="header" href="#load-custom-edid">Load Custom EDID</a></h2>
<ol>
<li>
<p>Add or replace the file <code>/etc/kvmd/tc358743-edid.hex</code></p>
<pre><code class="language-text">00FFFFFFFFFFFF0052628888008888881C150103800000780AEE91A3544C99260F505425400001000100010001000100010001010101D32C80A070381A403020350040442100001E7E1D00A0500019403020370080001000001E000000FC0050492D4B564D20566964656F0A000000FD00323D0F2E0F000000000000000001C402030400DE0D20A03058122030203400F0B400000018E01500A04000163030203400000000000018B41400A050D011203020350080D810000018AB22A0A050841A3030203600B00E1100001800000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000045
</code></pre>
</li>
<li>
<p>Restart kvmd</p>
<pre><code class="language-sh">systemctl restart kvmd.service
</code></pre>
</li>
</ol>
<h2 id="disable-ssl"><a class="header" href="#disable-ssl">Disable SSL</a></h2>
<ol>
<li>
<p>Add or replace the file <code>/etc/kvmd/nginx/nginx.conf</code></p>
<pre><code class="language-nginx">worker_processes 4;

error_log stderr;

include /usr/share/kvmd/extras/*/nginx.ctx-main.conf;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    types_hash_max_size 4096;
    server_names_hash_bucket_size 128;

    access_log off;

    include /etc/kvmd/nginx/mime-types.conf;
    default_type application/octet-stream;
    charset utf-8;

    sendfile on;
    tcp_nodelay on;
    tcp_nopush on;
    keepalive_timeout 10;
    client_max_body_size 4k;

    client_body_temp_path    /tmp/kvmd-nginx/client_body_temp;
    fastcgi_temp_path        /tmp/kvmd-nginx/fastcgi_temp;
    proxy_temp_path            /tmp/kvmd-nginx/proxy_temp;
    scgi_temp_path            /tmp/kvmd-nginx/scgi_temp;
    uwsgi_temp_path            /tmp/kvmd-nginx/uwsgi_temp;

    include /etc/kvmd/nginx/kvmd.ctx-http.conf;
    include /usr/share/kvmd/extras/*/nginx.ctx-http.conf;

    server {
        listen 80;
        listen [::]:80;
        server_name localhost;
        include /etc/kvmd/nginx/kvmd.ctx-server.conf;
        include /usr/share/kvmd/extras/*/nginx.ctx-server.conf;
    }
}
</code></pre>
</li>
<li>
<p>Restart kvmd-nginx</p>
<pre><code class="language-sh">systemctl restart kvmd-nginx.service
</code></pre>
</li>
</ol>
<h2 id="monitoring"><a class="header" href="#monitoring">Monitoring</a></h2>
<h3 id="install-node-exporter"><a class="header" href="#install-node-exporter">Install node-exporter</a></h3>
<pre><code class="language-sh">pacman -S prometheus-node-exporter
systemctl enable --now prometheus-node-exporter
</code></pre>
<h3 id="install-promtail"><a class="header" href="#install-promtail">Install promtail</a></h3>
<ol>
<li>
<p>Install promtail</p>
<pre><code class="language-sh">pacman -S promtail
systemctl enable promtail
</code></pre>
</li>
<li>
<p>Override the promtail systemd service</p>
<pre><code class="language-sh">mkdir -p /etc/systemd/system/promtail.service.d/
cat &gt;/etc/systemd/system/promtail.service.d/override.conf &lt;&lt;EOL
[Service]
Type=simple
ExecStart=
ExecStart=/usr/bin/promtail -config.file /etc/loki/promtail.yaml
EOL
</code></pre>
</li>
<li>
<p>Add or replace the file <code>/etc/loki/promtail.yaml</code></p>
<pre><code class="language-yaml">server:
  log_level: info
  disable: true

client:
  url: &quot;https://loki.devbu.io/loki/api/v1/push&quot;

positions:
  filename: /tmp/positions.yaml

scrape_configs:
  - job_name: journal
    journal:
      path: /run/log/journal
      max_age: 12h
      labels:
        job: systemd-journal
    relabel_configs:
      - source_labels: [&quot;__journal__systemd_unit&quot;]
        target_label: unit
      - source_labels: [&quot;__journal__hostname&quot;]
        target_label: hostname
</code></pre>
</li>
<li>
<p>Start promtail</p>
<pre><code class="language-sh">systemctl daemon-reload
systemctl start promtail.service
</code></pre>
</li>
</ol>
<footer id="open-on-gh"><a href="https://github.com/onedr0p/home-ops/edit/main/docs/src/notes/pikvm.md">Edit this page on GitHub</a></footer><div style="break-before: page; page-break-before: always;"></div><h1 id="proxmox-considerations"><a class="header" href="#proxmox-considerations">Proxmox Considerations</a></h1>
<p>I am using bare metal nodes but here's some considerations when using Kubernetes on Proxmox. These are just my opinions gathered from experiance I've witnessed first or second hand. I will always <strong>advocate for bare metal Kubernetes</strong> due to the overhead of VMs and disk concerns, however following along below will net you a very stable Kubernetes cluster on PVE.</p>
<div id="admonition-warning" class="admonition warning">
<div class="admonition-title">
<p>Warning</p>
<p><a class="admonition-anchor-link" href="notes/proxmox-considerations.html#admonition-warning"></a></p>
</div>
<div>
<p>Preface: etcd <strong>needs 3 master/control plane nodes for quorum</strong> also it is really read/write intensive and requires low iops/latency. With using the same disk for all master nodes and due to the way etcd works anytime a commit happens to etcd (which is probably hundreds of times per second), it will flood the same filesystem with 3x the amount of reads and writes</p>
<p>Now if you layer on Longhorn or rook-ceph to the <strong>same</strong> filesystem you are just asking for trouble, because that is also replicated.</p>
</div>
</div>
<h2 id="single-node-pve-cluster"><a class="header" href="#single-node-pve-cluster">Single Node PVE Cluster</a></h2>
<ol>
<li>Use physical separate disks used for the PVE install, k8s VMs and Longhorn/rook-ceph</li>
<li>Don't put k8s VMs or Longhorn/rook-ceph on HDDs, only use SSDs or NVMe</li>
<li>Use k3s with a single master node (4CPU/8GB RAM/50GB disk) that is using sqlite instead of etcd and taint it.</li>
<li>Use as many worker nodes as you want but start with 3 and add more later on if you need them.</li>
<li>Consider using <a href="https://github.com/rancher/local-path-provisioner">local-path-provisioner</a> over Longhorn or rook-ceph if you aren't able physically separate the disks.</li>
</ol>
<h2 id="dual-node-pve-cluster"><a class="header" href="#dual-node-pve-cluster">Dual node PVE Cluster</a></h2>
<p>Buy another node for your PVE cluster or refer to Single Node PVE Cluster, <em>however if you must...</em></p>
<ol>
<li>Use k3s with a dual master nodes (2vCPU/8GB RAM/50GB disk each) that is using postgresql/mariadb/mysql (in that order) instead of etcd.</li>
<li>Put the postgresql/mysql/mariadb database on a VM on your first PVE cluster. However, without some architecting this means that your cluster store is not highly available and is a single point of failure.</li>
<li>Evenly spread out your k8s masters and workers across each PVE node
<ul>
<li>In a 2 master/3 worker setup put one master on each PVE node and try to even out the workers on each PVE node.</li>
</ul>
</li>
<li>Consider using <a href="https://github.com/rancher/local-path-provisioner">local-path-provisioner</a> for application config data over Longhorn or rook-ceph if you aren't able physically separate the disks between Proxmox, VMs and Longhorn/rook-ceph.</li>
</ol>
<h2 id="tripe-node-pve-cluster"><a class="header" href="#tripe-node-pve-cluster">Tripe node PVE Cluster</a></h2>
<ol>
<li>Use physical separate disks used for the PVE install, k8s VMs and Longhorn</li>
<li>Don't put k8s VMs or Longhorn on HDDs, only use SSDs or NVMe</li>
<li>Evenly spread out your k8s masters and workers across each PVE node
<ul>
<li>In a 3 master/3 worker setup put one master on each PVE node and one worker on each PVE node.</li>
</ul>
</li>
<li>Instead of Longhorn, consider setting up a <a href="https://pve.proxmox.com/wiki/Deploy_Hyper-Converged_Ceph_Cluster">Ceph cluster on your PVE nodes</a> and use <a href="https://rook.io/docs/rook/v1.10/CRDs/Cluster/external-cluster/">Rook to consume it</a> for stateful applications. Due to the way Ceph works in this scenerio, it is fine to use HDDs over SSDs or NVMe here.</li>
</ol>
<footer id="open-on-gh"><a href="https://github.com/onedr0p/home-ops/edit/main/docs/src/notes/proxmox-considerations.md">Edit this page on GitHub</a></footer><div style="break-before: page; page-break-before: always;"></div><h1 id="s3-buckets"><a class="header" href="#s3-buckets">S3 buckets</a></h1>
<p>Alternatively creating s3 buckets can be automated with Terraform.</p>
<h2 id="b2"><a class="header" href="#b2">b2</a></h2>
<div id="admonition-info" class="admonition info">
<div class="admonition-title">
<p>Info</p>
<p><a class="admonition-anchor-link" href="notes/s3-buckets.html#admonition-info"></a></p>
</div>
<div>
<p>This requires installing the Backblaze <code>b2</code> CLI tool</p>
</div>
</div>
<h3 id="creating-a-bucket"><a class="header" href="#creating-a-bucket">Creating a bucket</a></h3>
<ol>
<li>
<p>Create master <code>key-id</code> and <code>key</code> on <a href="https://secure.backblaze.com/app_keys.htm">Account &gt; App Keys</a></p>
</li>
<li>
<p>Export settings</p>
<pre><code class="language-sh">export B2_APPLICATION_KEY_ID=&quot;&lt;key-id&gt;&quot;
export B2_APPLICATION_KEY=&quot;&lt;key&gt;&quot;
export B2_BUCKET_NAME=&quot;&lt;bucket-name&gt;&quot;
</code></pre>
</li>
<li>
<p>Create the bucket</p>
<pre><code class="language-sh">b2 create-bucket &quot;${B2_BUCKET_NAME}&quot; allPrivate \
  --defaultServerSideEncryption &quot;SSE-B2&quot;  \
  --lifecycleRules '[{&quot;daysFromHidingToDeleting&quot;: 1,&quot;daysFromUploadingToHiding&quot;: null,&quot;fileNamePrefix&quot;: &quot;&quot;}]'
</code></pre>
</li>
<li>
<p>Create the bucket username and password</p>
<pre><code class="language-sh">b2 create-key --bucket &quot;${B2_BUCKET_NAME}&quot; &quot;${B2_BUCKET_NAME}&quot; \
  listBuckets,readBuckets,listFiles,readFiles,writeFiles,readBucketEncryption,readBucketReplications,readBucketRetentions,readFileRetentions,writeFileRetentions,readFileLegalHolds
</code></pre>
</li>
</ol>
<h2 id="minio"><a class="header" href="#minio">Minio</a></h2>
<div id="admonition-info-1" class="admonition info">
<div class="admonition-title">
<p>Info</p>
<p><a class="admonition-anchor-link" href="notes/s3-buckets.html#admonition-info-1"></a></p>
</div>
<div>
<p>This requires installing the Minio <code>mc</code> CLI tool</p>
</div>
</div>
<h3 id="creating-a-bucket-1"><a class="header" href="#creating-a-bucket-1">Creating a Bucket</a></h3>
<ol>
<li>
<p>Create the Minio CLI configuration file (<code>~/.mc/config.json</code>)</p>
<pre><code class="language-sh">mc alias set minio &quot;https://s3.&lt;domain&gt;.&lt;tld&gt;&quot; &quot;&lt;access-key&gt;&quot; &quot;&lt;secret-key&gt;&quot;
</code></pre>
</li>
<li>
<p>Export settings</p>
<pre><code class="language-sh">export BUCKET_NAME=&quot;&lt;bucket-name&gt;&quot; # also used for the bucket username
export BUCKET_PASSWORD=&quot;$(openssl rand -hex 20)&quot;
echo $BUCKET_PASSWORD
</code></pre>
</li>
<li>
<p>Create the bucket username and password</p>
<pre><code class="language-sh">mc admin user add minio &quot;${BUCKET_NAME}&quot; &quot;${BUCKET_PASSWORD}&quot;
</code></pre>
</li>
<li>
<p>Create the bucket</p>
<pre><code class="language-sh">mc mb &quot;minio/${BUCKET_NAME}&quot;
</code></pre>
</li>
<li>
<p>Create the user policy document</p>
<pre><code class="language-sh">cat &lt;&lt;EOF &gt; /tmp/user-policy.json
{
    &quot;Version&quot;: &quot;2012-10-17&quot;,
    &quot;Statement&quot;: [
        {
            &quot;Action&quot;: [
                &quot;s3:ListBucket&quot;,
                &quot;s3:PutObject&quot;,
                &quot;s3:GetObject&quot;,
                &quot;s3:DeleteObject&quot;
            ],
            &quot;Effect&quot;: &quot;Allow&quot;,
            &quot;Resource&quot;: [&quot;arn:aws:s3:::${BUCKET_NAME}/*&quot;, &quot;arn:aws:s3:::${BUCKET_NAME}&quot;],
            &quot;Sid&quot;: &quot;&quot;
        }
    ]
}
EOF
</code></pre>
</li>
<li>
<p>Apply the bucket policies</p>
<pre><code class="language-sh">mc admin policy add minio &quot;${BUCKET_NAME}-private&quot; /tmp/user-policy.json
</code></pre>
</li>
<li>
<p>Associate private policy with the user</p>
<pre><code class="language-sh">mc admin policy set minio &quot;${BUCKET_NAME}-private&quot; &quot;user=${BUCKET_NAME}&quot;
</code></pre>
</li>
</ol>
<h4 id="allow-public-access-to-certain-objects-in-the-bucket"><a class="header" href="#allow-public-access-to-certain-objects-in-the-bucket">Allow public access to certain objects in the bucket</a></h4>
<div id="admonition-info-2" class="admonition info">
<div class="admonition-title">
<p>Info</p>
<p><a class="admonition-anchor-link" href="notes/s3-buckets.html#admonition-info-2"></a></p>
</div>
<div>
<p>This step is optional and not needed unless you want to make certain objects public to the internet</p>
</div>
</div>
<ol>
<li>
<p>Create the bucket policy document and update the folders that should be public</p>
<pre><code class="language-sh">cat &lt;&lt;EOF &gt; /tmp/bucket-policy.json
{
    &quot;Version&quot;: &quot;2012-10-17&quot;,
    &quot;Statement&quot;: [
        {
            &quot;Effect&quot;: &quot;Allow&quot;,
            &quot;Principal&quot;: {
                &quot;AWS&quot;: [
                    &quot;*&quot;
                ]
            },
            &quot;Action&quot;: [
                &quot;s3:GetBucketLocation&quot;
            ],
            &quot;Resource&quot;: [
                &quot;arn:aws:s3:::${BUCKET_NAME}&quot;
            ]
        },
        {
            &quot;Effect&quot;: &quot;Allow&quot;,
            &quot;Principal&quot;: {
                &quot;AWS&quot;: [
                    &quot;*&quot;
                ]
            },
            &quot;Action&quot;: [
                &quot;s3:ListBucket&quot;
            ],
            &quot;Resource&quot;: [
                &quot;arn:aws:s3:::${BUCKET_NAME}&quot;
            ],
            &quot;Condition&quot;: {
                &quot;StringEquals&quot;: {
                    &quot;s3:prefix&quot;: [
                        &quot;avatars&quot;,
                        &quot;public&quot;
                    ]
                }
            }
        },
        {
            &quot;Effect&quot;: &quot;Allow&quot;,
            &quot;Principal&quot;: {
                &quot;AWS&quot;: [
                    &quot;*&quot;
                ]
            },
            &quot;Action&quot;: [
                &quot;s3:GetObject&quot;
            ],
            &quot;Resource&quot;: [
                &quot;arn:aws:s3:::${BUCKET_NAME}/avatars*&quot;,
                &quot;arn:aws:s3:::${BUCKET_NAME}/public*&quot;
            ]
        }
    ]
}
EOF
</code></pre>
</li>
<li>
<p>Associate public policy with the bucket</p>
<pre><code class="language-sh">mc anonymous set-json /tmp/bucket-policy.json &quot;minio/${BUCKET_NAME}&quot;
</code></pre>
</li>
</ol>
<h3 id="sharing-an-object-in-a-bucket"><a class="header" href="#sharing-an-object-in-a-bucket">Sharing an object in a bucket</a></h3>
<pre><code class="language-sh">mc share download --expire=7d &quot;minio/&lt;bucket-name&gt;/&lt;file&gt;.&lt;ext&gt;&quot; --json  | jq -r .share | pbcopy
</code></pre>
<footer id="open-on-gh"><a href="https://github.com/onedr0p/home-ops/edit/main/docs/src/notes/s3-buckets.md">Edit this page on GitHub</a></footer><div style="break-before: page; page-break-before: always;"></div><h1 id="secret-variations-with-flux"><a class="header" href="#secret-variations-with-flux">Secret variations with Flux</a></h1>
<p>There are several different ways to utilize Kubernetes secrets when using <a href="https://fluxcd.io/">Flux</a> and <a href="https://github.com/mozilla/sops">SOPS</a>, here‚Äôs a breakdown of some common methods.</p>
<p><em>I will not be covering how to integrate SOPS into Flux for that be sure to check out the <a href="https://fluxcd.io/docs/guides/mozilla-sops/">Flux documentation on integrating SOPS</a></em></p>
<h2 id="example-secret"><a class="header" href="#example-secret">Example Secret</a></h2>
<div id="admonition-info" class="admonition info">
<div class="admonition-title">
<p>Info</p>
<p><a class="admonition-anchor-link" href="notes/secret-variations-with-flux.html#admonition-info"></a></p>
</div>
<div>
<p>The three following methods will use this secret as an example.</p>
</div>
</div>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: application-secret
  namespace: default
stringData:
  AWESOME_SECRET: &quot;SUPER SECRET VALUE&quot;
</code></pre>
<h3 id="method-1-envfrom"><a class="header" href="#method-1-envfrom">Method 1: <code>envFrom</code></a></h3>
<blockquote>
<p><em>Use <code>envFrom</code> in a deployment or a Helm chart that supports the setting, this will pass all secret items from the secret into the containers environment.</em></p>
</blockquote>
<pre><code class="language-yaml">envFrom:
  - secretRef:
      name: application-secret
</code></pre>
<div id="admonition-example" class="admonition example">
<div class="admonition-title">
<p>Example</p>
<p><a class="admonition-anchor-link" href="notes/secret-variations-with-flux.html#admonition-example"></a></p>
</div>
<div>
<p>View example <a href="https://ln.devbu.io/ngLju">Helm Release</a> and corresponding <a href="https://ln.devbu.io/ULgnl">Secret</a>.</p>
</div>
</div>
<h3 id="method-2-envvaluefrom"><a class="header" href="#method-2-envvaluefrom">Method 2: <code>env.valueFrom</code></a></h3>
<blockquote>
<p><em>Similar to the above but it's possible with <code>env</code> to pick an item from a secret.</em></p>
</blockquote>
<pre><code class="language-yaml">env:
  - name: WAY_COOLER_ENV_VARIABLE
    valueFrom:
      secretKeyRef:
        name: application-secret
        key: AWESOME_SECRET
</code></pre>
<div id="admonition-example-1" class="admonition example">
<div class="admonition-title">
<p>Example</p>
<p><a class="admonition-anchor-link" href="notes/secret-variations-with-flux.html#admonition-example-1"></a></p>
</div>
<div>
<p>View example <a href="https://ln.devbu.io/0lbMT">Helm Release</a> and corresponding <a href="https://ln.devbu.io/KYjhP">Secret</a>.</p>
</div>
</div>
<h3 id="method-3-specvaluesfrom"><a class="header" href="#method-3-specvaluesfrom">Method 3: <code>spec.valuesFrom</code></a></h3>
<blockquote>
<p><em>The Flux HelmRelease option <code>valuesFrom</code> can inject a secret item into the Helm values of a <code>HelmRelease</code></em></p>
<ul>
<li><em>Does not work with merging array values</em></li>
<li><em>Care needed with keys that contain dot notation in the name</em></li>
</ul>
</blockquote>
<pre><code class="language-yaml">valuesFrom:
  - targetPath: config.&quot;admin\.password&quot;
    kind: Secret
    name: application-secret
    valuesKey: AWESOME_SECRET
</code></pre>
<div id="admonition-example-2" class="admonition example">
<div class="admonition-title">
<p>Example</p>
<p><a class="admonition-anchor-link" href="notes/secret-variations-with-flux.html#admonition-example-2"></a></p>
</div>
<div>
<p>View example <a href="https://ln.devbu.io/ARdun">Helm Release</a> and corresponding <a href="https://ln.devbu.io/hNef8">Secret</a>.</p>
</div>
</div>
<h3 id="method-4-variable-substitution-with-flux"><a class="header" href="#method-4-variable-substitution-with-flux">Method 4: Variable Substitution with Flux</a></h3>
<blockquote>
<p><em>Flux variable substitution can inject secrets into any YAML manifest. This requires the <a href="https://fluxcd.io/docs/components/kustomize/kustomization/">Flux Kustomization</a> configured to enable <a href="https://fluxcd.io/docs/components/kustomize/kustomization/#variable-substitution">variable substitution</a>. Correctly configured this allows you to use <code>${GLOBAL_AWESOME_SECRET}</code> in any YAML manifest.</em></p>
</blockquote>
<pre><code class="language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: cluster-secrets
  namespace: flux-system
stringData:
  GLOBAL_AWESOME_SECRET: &quot;GLOBAL SUPER SECRET VALUE&quot;
</code></pre>
<pre><code class="language-yaml">apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
# ...
spec:
# ...
  decryption:
    provider: sops
    secretRef:
      name: sops-age
  postBuild:
    substituteFrom:
      - kind: Secret
        name: cluster-secrets
</code></pre>
<div id="admonition-example-3" class="admonition example">
<div class="admonition-title">
<p>Example</p>
<p><a class="admonition-anchor-link" href="notes/secret-variations-with-flux.html#admonition-example-3"></a></p>
</div>
<div>
<p>View example <a href="https://ln.devbu.io/ZMbfI">Fluxtomization</a>, <a href="https://ln.devbu.io/y6DJS">Helm Release</a>, and corresponding <a href="https://ln.devbu.io/kRoHj">Secret</a>.</p>
</div>
</div>
<h2 id="final-thoughts"><a class="header" href="#final-thoughts">Final Thoughts</a></h2>
<ul>
<li>
<p>For the first <strong>three methods</strong> consider using a tool like <a href="https://github.com/stakater/Reloader">stakater/reloader</a> to restart the pod when the secret changes.</p>
</li>
<li>
<p>Using reloader on a pod using a secret provided by Flux Variable Substitution will lead to pods being restarted during any change to the secret while related to the pod or not.</p>
</li>
<li>
<p>The last method should be used when all other methods are not an option, or used when you have a ‚Äúglobal‚Äù secret used by a bunch of YAML manifests.</p>
</li>
</ul>
<footer id="open-on-gh"><a href="https://github.com/onedr0p/home-ops/edit/main/docs/src/notes/secret-variations-with-flux.md">Edit this page on GitHub</a></footer><div style="break-before: page; page-break-before: always;"></div><h1 id="yaml-madness"><a class="header" href="#yaml-madness">YAML Madness</a></h1>
<p>YAML aliases, anchors and overrides are a great way to keep your manifests DRY (<strong>D</strong>o not <strong>R</strong>epeat <strong>Y</strong>ourself) but only on a very basic level.</p>
<h2 id="anchors-and-aliases"><a class="header" href="#anchors-and-aliases">Anchors and Aliases</a></h2>
<div id="admonition-note" class="admonition note">
<div class="admonition-title">
<p>Note</p>
<p><a class="admonition-anchor-link" href="notes/yaml-madness.html#admonition-note"></a></p>
</div>
<div>
<p>The anchor operator <strong>&amp;</strong> is a way to define a variable and the alias character <strong>*</strong> is a way to reference the value defined in the anchor.</p>
</div>
</div>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: &amp;app &quot;awesome-app&quot;
  namespace: default
  labels:
    app.kubernetes.io/name: *app
</code></pre>
<p><em>this will be rendered out to...</em></p>
<pre><code class="language-yaml">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: awesome-app
  namespace: default
  labels:
    app.kubernetes.io/name: &quot;awesome-app&quot;
</code></pre>
<h2 id="overrides"><a class="header" href="#overrides">Overrides</a></h2>
<div id="admonition-note-1" class="admonition note">
<div class="admonition-title">
<p>Note</p>
<p><a class="admonition-anchor-link" href="notes/yaml-madness.html#admonition-note-1"></a></p>
</div>
<div>
<p>The <strong>&lt;&lt;</strong> operator allows referencing a block of YAML as many times as needed.</p>
</div>
</div>
<pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: &amp;app &quot;awesome-app&quot;
  namespace: default
  labels: &amp;labels
    app.kubernetes.io/instance: *app
    app.kubernetes.io/name: *app
spec:
  selector:
    matchLabels:
      &lt;&lt;: *labels
</code></pre>
<p><em>this will be rendered out to...</em></p>
<pre><code class="language-yaml">apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: &quot;awesome-app&quot;
  namespace: default
  labels:
    app.kubernetes.io/instance: &quot;awesome-app&quot;
    app.kubernetes.io/name: &quot;awesome-app&quot;
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: &quot;awesome-app&quot;
      app.kubernetes.io/name: &quot;awesome-app&quot;
</code></pre>
<h2 id="important-notes"><a class="header" href="#important-notes">Important Notes</a></h2>
<ul>
<li>Defining an anchor, alias or override cannot be referenced in separate YAML docs whether it is in the same file or not.</li>
<li>You absolutely cannot concat, or do any advanced string functions on anchors, aliases or overrides.</li>
<li>Try to make sure your YAML is comprehensible, don't get hung up on making DRY an absolute rule to follow.</li>
</ul>
<footer id="open-on-gh"><a href="https://github.com/onedr0p/home-ops/edit/main/docs/src/notes/yaml-madness.md">Edit this page on GitHub</a></footer>
                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>






        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
